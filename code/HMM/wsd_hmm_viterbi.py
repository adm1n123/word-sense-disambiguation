# -*- coding: utf-8 -*-
"""WSD_HMM_Viterbi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pQ1SOkdnHLQah2Hu4rBYOLMeEgJNTirW
"""

!pip install nltk==3.5

from datetime import datetime
import random

import nltk
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sn

nltk.download('semcor')
from nltk.corpus import semcor

nltk.download('wordnet')
from nltk.corpus import wordnet
from nltk.tree import Tree

from sklearn.model_selection import KFold
from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix

# for testing single sentence
TEST = False

KFOLD = 5
COUNT_KEY = 'count'
START_SENSE = '^'
END_SENSE = '.'
NO_SENSE = '<NoSense>'
EPSILON = 1e-9
NO_WORD = '<NAW>'
NAMED_ENTITY = 'NE'
MAX_SENSES = 20000

class HMM:

    def __init__(self):
        self.tagged_sents = semcor.tagged_sents(tag='sem')

        self.train_sents = None
        self.test_sents = None

        self.words_dict = None
        self.senses_dict = None

        self.em_table = None  # P(w/t)
        # self.em_table_df = None
        self.tran_table = None  # P(t2/t1)
        self.tran_table_df = None

        self.senses, self.cstm_senses, self.vocab, self.word_id, self.sense_id, self.word_senses = None, None, None, None, None, None
        # self.senses has NO_SENSE at the end.  self.vocab has NO_WORD in the beginning.
        # self.sense_id it does not have NO_SENSE.
        self.sense_info = {}  # used in analysis only.

    def getSensesVocab(self):
        print('Getting Vocab')
        vocab = set()
        w_count, sent_count = 0, 0
        senses = {}

        for sent in self.train_sents:
            sent_count += 1
            for word, sense in sent:
                vocab.add(word)
                senses[sense] = senses.get(sense, 0) + 1
                w_count += 1

        senses = sorted(senses.items(), key=lambda item: item[1], reverse=True)

        print(f'\nFound:{len(senses)} senses, and {len(vocab)} words')
        print(f'senses: {senses}')
        print(f'vocab: {sorted(vocab)}')
        print(f'Total words:{w_count}, total sents:{sent_count}')

        senses = senses[:MAX_SENSES]
        senses = set(sense for sense, count in senses)
        print(f'Using Top {MAX_SENSES} senses only. {senses}')

        word_senses = {word: set() for word in vocab}
        for sent in self.train_sents:
            for word, sense in sent:
                if sense in senses:                 # take frequent senses only.
                    word_senses[word].add(sense)

        for word, val in word_senses.items():   # add no sense to rest of the words.
            if len(val) == 0:
                val.add(NO_SENSE)

        senses, vocab = list(senses - {NO_SENSE}), [NO_WORD] + list(vocab)
        cstm_senses = [NO_SENSE, START_SENSE] + senses
        word_id = {word: idx for idx, word in enumerate(vocab)}
        sense_id = {sense: idx for idx, sense in enumerate(cstm_senses)}
        return senses, cstm_senses, vocab, word_id, sense_id, word_senses


    def computeStats(self):
        self.words_dict = {word: dict() for word in self.vocab}
        self.senses_dict = {sense: dict() for sense in self.cstm_senses}

        for sent in self.train_sents:
            prev_sense = START_SENSE
            self.senses_dict[START_SENSE][COUNT_KEY] = self.senses_dict[START_SENSE].get(COUNT_KEY, 0) + 1

            for word, sense in sent:
                if sense not in self.cstm_senses:
                    prev_sense = NO_SENSE
                    # TODO: if two NO_SENSE are consecutive then? if actual NO_SENSE comes then? self.senses does not have NO_SENSE.
                    continue

                self.words_dict[word][COUNT_KEY] = self.words_dict[word].get(COUNT_KEY, 0) + 1
                self.words_dict[word][sense] = self.words_dict[word].get(sense, 0) + 1

                self.senses_dict[sense][COUNT_KEY] = self.senses_dict[sense].get(COUNT_KEY, 0) + 1
                self.senses_dict[prev_sense][sense] = self.senses_dict[prev_sense].get(sense, 0) + 1

                prev_sense = sense

    def createEmissionTable(self):
        count, total = 0, len(self.train_sents)

        self.em_table = {word: dict() for word in self.vocab}

        for sent in self.train_sents:
            count += 1
            if count % 1000 == 0:
                print(f'\r progress {count * 100 / total:.2f}% done', end='')

            for word, sense in sent:
                if sense not in self.cstm_senses:
                    continue
                # old = self.em_table[word].get(sense, 0)
                # add = self.senses_dict[sense].get(COUNT_KEY, 1e9)
                self.em_table[word][sense] = self.em_table[word].get(sense, 0) + 1 / self.senses_dict[sense].get(COUNT_KEY, 1e9)
                # new =  self.em_table[word][sense]

        print()
        # self.em_table_df = pd.DataFrame(self.em_table, index=self.vocab, columns=self.senses)


    def createTransitionTable(self):
        count, total = 0, len(self.train_sents)

        self.tran_table = np.full((len(self.cstm_senses), len(self.cstm_senses)), EPSILON)

        for sent in self.train_sents:
            count += 1
            if count % 1000 == 0:
                print(f'\r progress {count * 100 / total:.2f}% done', end='')

            t1 = START_SENSE
            for _, t2 in sent:
                if t2 not in self.cstm_senses:
                    t1 = NO_SENSE
                    continue
                # TODO: what if two NO_SENSE are consecutive. we are considering actual NO_SENSE in train data. (not because of filtered senses).
                self.tran_table[self.sense_id[t2]][self.sense_id[t1]] += 1 / self.senses_dict[t1].get(COUNT_KEY, 1e9)
                t1 = t2

        print()
        # self.tran_table_df = pd.DataFrame(self.tran_table, index=self.senses, columns=[START_SENSE] + self.senses)


    def train(self):
        self.train_sents = self.modifySenses(self.train_sents)
        self.senses, self.cstm_senses, self.vocab, self.word_id, self.sense_id, self.word_senses = self.getSensesVocab()
        self.senses.append(NO_SENSE)
        self.sense_info = {sense: dict() for sense in self.senses}

        print('Computing stats...')
        self.computeStats()
        print('Computing emission probability ...')
        self.createEmissionTable()
        print('Computing transition probability')
        self.createTransitionTable()


    def test(self):
        self.test_sents = self.modifySenses(self.test_sents)
        print('Running Test')
        prediction = []

        count = 0
        total = 100

        for sent in self.test_sents:
            if count == 100:
                break

            count += 1
            if count % 1 == 0:
                print(f'\rTesting...{count}/{total}.   {count*100/total:.2f}% done', end='')

            states = {START_SENSE: {'prob': 1, 'ptr': None}}

            DP = [states]
            CORRECT_SENSES = [START_SENSE]
            WORDS = [START_SENSE]

            for word, sense in sent:
                word = word.lower()
                # if word == END_SENSE:
                #     continue
                # word_idx = self.word_id.get(word, 0)

                CORRECT_SENSES.append(sense)
                WORDS.append(word)

                states = {word_sense: {'prob': 5e-324, 'ptr': None} for word_sense in self.word_senses.get(word, {NO_SENSE})}

                if self.em_table.get(word) is None: # for new words.
                    max_prob, last_sense = 0, None
                    for sns, val in DP[-1].items():
                        if val['prob'] > max_prob:
                            max_prob, last_sense = val['prob'], sns

                    states[NO_SENSE]['prob'] = 1
                    states[NO_SENSE]['ptr'] = last_sense
                    DP.append(states)
                    continue


                max_prob = 0
                for t2 in states.keys():   # traverse for senses of this word only. if word is new return NO_SENSE.
                    if self.sense_id.get(t2, None) is None:
                        print("error")

                    row = self.sense_id[t2]
                    for t1 in DP[-1].keys(): # TODO: use only modified tags in last iteration. valid_last_state = sense of last word.
                        col = self.sense_id[t1]
                        t2_prob = DP[-1][t1]['prob'] * self.tran_table[row][col] * self.em_table[word].get(t2, EPSILON)

                        if t1 != START_SENSE:   # TODO: remove this what is use of it.
                            t2_prob = max(t2_prob, 5e-324)

                        if t2_prob > states[t2]['prob']:
                            states[t2]['prob'] = t2_prob
                            states[t2]['ptr'] = t1

                    max_prob = max(max_prob, states[t2]['prob'])

                if max_prob < 1e-100 and max_prob != 0:
                    for _, val in states.items():
                        val['prob'] *= 1 / max_prob

                DP.append(states)

            DP.reverse()
            CORRECT_SENSES.reverse()
            WORDS.reverse()

            max_prob, pred_sense = 0, None
            for sense, val in DP[0].items():
                if val['prob'] > max_prob:
                    max_prob, pred_sense = val['prob'], sense

            for state, sense, word in zip(DP[:-1], CORRECT_SENSES[:-1], WORDS[:-1]):
                # if TEST:
                #     print(f'Word: {word}, sense: {sense}, pred_sense: {pred_sense}')

                # if sense == 'foot.n.02' and pred_sense == 'foot.n.01':
                #     print(" #################################################   sense is foot", word)
                    
                # if sense == 'think.v.02' and pred_sense == 'think.v.01':
                #     print(" #################################################   sense is think", word)

                # if sense == 'own.v.01' and pred_sense == 'have.v.01':
                #     print(" #################################################   sense is own ", word)

                # if sense == 'yield.v.01' and pred_sense == 'give.v.01':
                #     print(" #################################################   sense is yield", word)

                # if sense == 'receive.v.02' and pred_sense == 'get.v.01':
                #     print(" #################################################   sense is receive", word)


                prediction.append([sense, pred_sense])
                pred_sense = state[pred_sense]['ptr']

        print()
        return prediction


    def analysis(self, prediction):
        y_true, y_pred = [], []
        for sense, pred_sense in prediction:
            y_true.append(sense)
            y_pred.append(pred_sense)

        self.findConfusionCases(y_true, y_pred)

        # report1 = classification_report(y_true, y_pred, output_dict=True)
        report1 = precision_recall_fscore_support(y_true, y_pred, average='weighted', beta=1)
        report05 = precision_recall_fscore_support(y_true, y_pred, average='weighted', beta=0.5)
        report2 = precision_recall_fscore_support(y_true, y_pred, average='weighted', beta=2.0)

        print(f'\n\n\n#################### Analysis ####################')
        self.sense_info[COUNT_KEY] = self.sense_info.get(COUNT_KEY, 0) + 1
        flag = False
        for report, name in [(report1, 'f1'), (report05, 'f0.5'), (report2, 'f2')]:
            p, r, f, s = report
            if not flag:
                print(f"Precision: {100*p:.2f}%, Recall: {100*r:.2f}%,    {name}: {100*f:.2f}%")
                self.sense_info['P'] = self.sense_info.get('P', 0) + p
                self.sense_info['R'] = self.sense_info.get('R', 0) + r
                self.sense_info[name] = self.sense_info.get(name, 0) + f
                flag = True
            else:
                print(f"{name}: {100*f:.2f}%")
                self.sense_info[name] = self.sense_info.get(name, 0) + f


    def findConfusionCases(self, y_true, y_pred):
        labels = list(set(y_true+y_pred))
        cf_matrix = confusion_matrix(y_true, y_pred, labels=labels)
        confusion_list = []
        for row, r_label in enumerate(labels):
            for col, c_label in enumerate(labels):
                confusion_list.append([r_label, c_label, cf_matrix[row][col]])

        confusion_list = sorted(confusion_list, key=lambda x: x[2], reverse=True)
        print(f'Top 100 confusion cases:{confusion_list[:100]}')


    def modifySenses(self, sents):
        print('Preprocessing corpus(modifying senses)', time())
        modified_sents = []
        count = 0
        total = 37176 # len(self.tagged_sents) takes unnecessary time precomputing is better.

        for sent in sents:
            count += 1
            if count % 1000 == 0:
                print(f'\rModifying...{count}/{total}.    {count*100/total:.2f}% done', end='')

            modified_sent = []
            for word_tree in sent:
                if isinstance(word_tree, nltk.Tree):
                    word = '_'.join(word_tree.leaves())
                    try:
                        sense = word_tree.label().synset().name()
                    except:
                        if word_tree.label() == NAMED_ENTITY:
                            sense = NAMED_ENTITY
                        else:
                            sense = word_tree.label()
                else:
                    # print(word_tree)
                    sense = NO_SENSE
                    word = '_'.join(word_tree)  # eg. word = ['of', 'this'] so we combine this as 'of_this'


                modified_sent.append((word.lower(), sense))
            modified_sents.append(modified_sent)

        print("\n", modified_sents[:5])
        # self.tagged_sents = random.sample(modified_sents, 1000)
        return modified_sents


def time():
    now = datetime.now()
    current_time = now.strftime("%H:%M:%S")
    return current_time


def main():
    hmm = HMM()

    kfold = KFold(n_splits=KFOLD, shuffle=True, random_state=42)  # set random_state=None later setting seed to reproduce result over multiple calls.

    for fold, (train_idx, test_idx) in enumerate(kfold.split(hmm.tagged_sents)):
        print(f'\n\n#####       Running fold number: {fold + 1}       #####')
        hmm.train_sents = map(hmm.tagged_sents.__getitem__, train_idx)
        hmm.test_sents = map(hmm.tagged_sents.__getitem__, test_idx)

        hmm.train_sents = [sent for sent in hmm.train_sents]
        hmm.test_sents = [sent for sent in hmm.test_sents]

        hmm.train()
        prediction = hmm.test()
        # print(prediction)
        hmm.analysis(prediction)

    count = hmm.sense_info[COUNT_KEY]
    print(f'Final Precision:{100*hmm.sense_info["P"]/count:.2f}%,     Recall: {100*hmm.sense_info["R"]/count:.2f}%,   '
          f'f1:{100*hmm.sense_info["f1"]/count:.2f}%,    f0.5:{100*hmm.sense_info["f0.5"]/count:.2f}%,    f2:{100*hmm.sense_info["f2"]/count:.2f}%')



if __name__ == '__main__':
    main()